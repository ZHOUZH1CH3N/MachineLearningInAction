# MachineLearningInAction
# 1.4 选择合适的算法
## 首先考虑使用机器学习算法的目的。
1. 如果想要预测目标变量的值，则可以选择监督学习算法，否则可以选择无监督学习算法。确定选择监督学习算法之后，需要进一步确定目标变量类型，如果目标变量类型是离散型，如是/否、1/2/3、A/B/C或者红/黄/黑等，则可以选择分类器算法；如果目标变量是连续型的数值，如0.0 ~ 100.00、-999 ~ 999等，则需要选择回归算法。
2. 如果不想预测目标变量的值，则可以选择无监督学习算法。进一步分析是否需要将数据划分为离散的组。如果这是唯一的需求，则使用聚类算法；如果还需要估计数据与每个分组之间的相似程度，则需要使用密度估计算法。
3. 还需要考虑数据问题。主要需要注意的是特征值是离散型变量还是连续型变量、特征值中是否存在缺失的值、何种原因造成缺失值、数据中是否存在异常值、某个特征发生的频率如何等等。
4. 一般来说最好算法的关键环节是反复试错的迭代过程。
# 1.5 开发机器学习应用程序的步骤
1. 收集数据。
2. 准备输入数据。
3. 分析输入数据。最简单的方法是用文本编辑器打开数据文件，查看得到的数据是否为空值。这一步的主要作用是确保数据集中没有垃圾数据。这一步可以跳过。
4. 训练算法。将前两步得到的格式化数据输入到算法，从中抽取知识或信息。若使用无监督学习算法，由于不存在目标变量值，故而也不需要训练算法。
5. 测试算法。对于监督学习，必须已知用于评估算法的目标变量值；对于无监督学习，必须用其他的评测手段来检验算法的成功率。若不满意算法的输出结果，则可以回到第4步，改正并加以测试。如果跟数据的收集和准备有关，必须跳回第1步重新开始。
6. 使用算法。将机器学习算法转换为应用程序，执行实际任务，检验上述步骤是否可以在实际环境中正常工作。如果碰到新的数据问题，需要重复执行上述步骤。
# 1.7 NumPy函数库
>rand函数根据给定维度生成[0,1)之间的数据，包含0，不包含1。

>NumPy函数库存在两种不同的数据类型，矩阵matrix和数组array。其中NumPy函数库中的matrix与MATLAB中的matrices等价。

>调用mat()函数可以将数组转化为矩阵。.I操作符实现矩阵求逆的运算。
# 2.1 k-近邻算法
>k-近邻算法采用测量不同特征值之间的距离方法进行分类。
>>优点：精度高、对异常值不敏感、无数据输入假定。

>>缺点：计算复杂度高、空间复杂度高。

>>适用数据范围：数值型和标称型。

>k-近邻算法的原理是：存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一个数据与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。一般来说，只选择样本数据集中前**k**个最相似的数据，这就是k-近邻算法中**k**的出处，通常k是不大于20的整数。最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。